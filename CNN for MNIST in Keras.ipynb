{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a CNN for MNIST with Keras\n",
    "CNNs or Convolutional Neural Networks are a special type of neural network which is particularly adept for computer vision problems. CNNs get their name from convolutions in mathematics which represent a relationship between two functions. CNNs are also inspired by the visual cortex of the brain.\n",
    "https://en.wikipedia.org/wiki/Convolutional_neural_network#Building_blocks\n",
    "\n",
    "MNIST is a well-known dataset for handwritten digit recognition. It is a popular benchmark for beginning machine learning. \n",
    "Data readily available through Kaggle:\n",
    "https://www.kaggle.com/c/digit-recognizer/data\n",
    "Additional benchmarks provided by Yann LeCun and friends:\n",
    "http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Keras is an emerging framework that abstracts Tensorflow and Theano. While these two frameworks abstract the algorithms and hardware for deep learning, Keras abstracts their \"language\" into one that is much closer to a natural language of deep learning.\n",
    "http://keras.io\n",
    "\n",
    "Today we will be going through our friend's example over at machinelearningmastery.com\n",
    "http://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data\n",
    "Before we get started, let's look at the data. The original tutorial provides a nice visualization of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# To make this work in a notebook, we need the following:\n",
    "%matplotlib inline\n",
    "\n",
    "# Import as usual\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we download the dataset. This may take a few seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAD+CAYAAABFjqJ0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b4cc208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what we're looking at, let's begin!\n",
    "\n",
    "## Multi-Layer Perceptron as a Baseline\n",
    "\n",
    "Before we build the convolutional neural net, it is wise for us to see how a much simpler model performs. To do so, we will use a multi-layer perceptron model.\n",
    "\n",
    "### Pre-processing for the multi-layer perceptron\n",
    "\n",
    "The next few steps will setup our script and our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors are good about setting the random seed in their demos. +1 for repeatable research!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since everything is in one notebook, we don't need to reload the data. I'll keep this here but comment it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test set comes in an intuitive format for humans a 3D array (image X width X height) but the input layer of our model is going to work on a \"rolled-out\" vector of each image. This is where NumPy comes in handy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "\n",
    "# Shape tells us the current shape (the array dims which are also our image dims)\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "\n",
    "# Reshape takes the \"new shape\" then we set the type to 32-bit float before assignment\n",
    "# So our new shape is 1Xnum_imagesXnum_pixels\n",
    "# The result is a 2D array of [num_images, num_pixels]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "# Repeat for test set\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our data in the structure we want. The original authors perform normalization which is common. The process is simple, conform a set of values of some range to one of range 0-1. https://en.wikipedia.org/wiki/Normalization_(statistics)\n",
    "\n",
    "As the authors at KDNuggets point out, this may only be important if the input features are of differing scales. This step of normalization is part of a \"pre-processing\" step which is necessary for almost any machine learning project. Other techniques include zero-centering or PCA whitening. http://www.kdnuggets.com/2016/03/must-know-tips-deep-learning-part-1.html\n",
    "\n",
    "However, it may not be such a bad idea to do it anyway: (1) so that we have them normalized, should we introduce more features (2) we develop the habit for when we build CNNs for other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional pre-processing is needed on the labels of the dataset. More specifically, we have to determine what type of output we expect from our CNN. As the authors point out, this is a multi-class classification problem. It is common to assign one activation unit per class in the output layer which outputs on a 0-1 scale. This results in a binary encoded output AKA one-hot encoded outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that np_utils is part of Keras, not NumPy. https://keras.io/utils/np_utils/\n",
    "\n",
    "From the documentation, we can see what to_categorical is doing:\n",
    "\"Convert class vector (integers from 0 to nb_classes) to binary class matrix, for use with categorical_crossentropy.\"\n",
    "\n",
    "So to_categorical() is expecting a 1D set of integers (in this case, our labels) and converting it to a 2D matrix of binary classes. That's a lot of abstraction from the old days of converting ints to bytes!\n",
    "\n",
    "Now that we have structured our inputs and outputs for a neural network. We can actually build the model.\n",
    "\n",
    "### Building the Baseline Multi-Layer Perceptron Model\n",
    "\n",
    "In Keras, we need to create a Sequential() object and make successive add() calls on that object to define the architecture of the network. We then need to \"compile\" the model which translates the architecture to the backend language (either TF or Theano). I won't go into as much detail about some Keras concepts as I did this with a previous tutorial from the same site. https://github.com/Shumakriss/MachineLearningTutorials/blob/master/Simple%20Neural%20Net%20in%20Keras.ipynb\n",
    "\n",
    "I will, however, try to go into detail about any parameter selections I have not used before.\n",
    "\n",
    "This is a little different than the previous examples. Here we are creating a method to return the model. I find it interesting that this method returns a new instance of a model. While it may serve to clean up the code, as a software engineer, it does not make this method seem particularly useful. I could see tweaking it to be a \\*gasp\\* singleton in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, init='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, init='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have a few new techniques:\n",
    "\n",
    "* Normal Distribution - We use a normal distribution instead of a uniform distribution like in our Simple Neural Net example. Either example helps break symmetry (unlike zero-initialization). It seems that initializing weights from a normal distribution was fairly standard prior to Xavier initialization which has come to be widely used and which samples from either a uniform or a Gaussian distribution.\n",
    "* Softmax Activiation - Previously we used relu and sigmoid activations. Softmax is a generalization of the logistic function (sigmoid) for multiple classes. More on Wikipedia https://en.wikipedia.org/wiki/Softmax_function#Artificial_neural_networks. I was wondering why we might want this since we have separate outputs for each class. It seems the answer is that we want to incorporate some \"mutual exclusitivity\" into the probability of each class. https://www.quora.com/Artificial-Neural-Networks-Why-do-we-use-softmax-function-for-output-layer. This helps us avoid situations where the probability of two or more classes being roughly the same.\n",
    "* Categorical Cross-entropy as a loss function - In the Simple Neural Net example, we used a binary cross-entropy loss function. Wikipedia is not too helpful https://en.wikipedia.org/wiki/Loss_functions_for_classification#Cross_entropy_loss for purposes of deep-learning but does provide some comparison of statistical loss functions. The Keras documentation, on the other hand, does provide some insight based on the available options: https://keras.io/objectives/. From the Keras docs, we can see that we have some regression-based loss functions and some classification-based log functions and we can infer that categorical cross-entropy is the mathematical term for a statistical method of classification. The term 'categorical' simply serves to distinguish the function as multi-class as opposed to 'binary' meaning just two classes (0 or 1).\n",
    "\n",
    "Other than these points, the rest of the Keras code for building a model is the same as in the Simple Neural Net example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating the Multi-layer perceptron Model\n",
    "\n",
    "After we define our model, we can call our function to initialize it. Once initialized, we can fit/train our model on our data. We will again set verbose=0 for the sake of our notebook. We will also set the argument validation_data to our test set. The Keras documentation says this will be used as data that will be held out. I would like to review this tutorial http://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/ to understand the specifics around validation_data and how it fits into a rigorous evaluation method. It is not obvious from the example and documentation how validation_data is used during training or if it is mathematically sound to use the same data in validation_data as the evaluate() data. Since this might be due to the quick-and-dirty nature of the baseline, I will save that for another day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 1.80%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=0)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "Now for the good stuff. We can begin working with CNNs in Keras.\n",
    "\n",
    "### Imports and Setup for CNN\n",
    "I want to keep this all in one notebook. For that reason, I will be removing some imports we have already incorporated. I am also commenting out the line where we set the image_dim_ordering to \"th\". This is to configure Theano for a backend, at least with regard to how image dimensions are specified. Since I have tensorflow installed on my machine and configured in a Keras config file, I will simply omit this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since this is the same code, we don't need all the imports from the original tutorial\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "# Uncomment if you do not have a Keras config file\n",
    "# Pass 'th' for Theano backend or 'tf' for Tensorflow, be sure to have the correct one installed\n",
    "# K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, commenting unecessary lines as we are in a single project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## fix random seed for reproducibility\n",
    "#seed = 7\n",
    "#numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do want to reset any changes we might have made to the training or test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing for CNN\n",
    "This time, we are going to be unrolling our images a bit differently. The original authors put it best, \"Next we need to load the MNIST dataset and reshape it so that it is suitable for use training a CNN. In Keras, the layers used for two-dimensional convolutions expect pixel values with the dimensions [pixels][width][height].\n",
    "\n",
    "In the case of RGB, the first dimension pixels would be 3 for the red, green and blue components and it would be like having 3 image inputs for every color image. In the case of MNIST where the pixel values are gray scale, the pixel dimension is set to 1.\"\n",
    "\n",
    "To paraphrase, typical CNNs (which work on images) expect an RGB format. So in addition to the number of images and the image dimensions, we also want to know how many channels are involved. But MNIST are in grayscale, we only need one dimension. This results in a list of pixel values in the same order but are technically grouped with an extra dimension. Later, when the convolution looks at the shape of the object, it will still have the \"channel\" dimension it is expecting even though it is only of value 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, some pre-processing is needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the CNN Model\n",
    "I really appreciate that the original authors utilize components for state-of-the-art (SOTA) results. This way, we can see a realistic example and expand on familiar concepts.\n",
    "\n",
    "I will also defer to the original authors for a summary of their CNN as it is fairly detailed but concise:\n",
    ">1. The first hidden layer is a convolutional layer called a Convolution2D. The layer has 32 feature maps, which with the size of 5×5 and a rectifier activation function. This is the input layer, expecting images with the structure outline above [pixels][width][height].\n",
    ">2. Next we define a pooling layer that takes the max called MaxPooling2D. It is configured with a pool size of 2×2.\n",
    ">3. The next layer is a regularization layer using dropout called Dropout. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n",
    ">4. Next is a layer that converts the 2D matrix data to a vector called Flatten. It allows the output to be processed by standard fully connected layers.\n",
    ">5. Next a fully connected layer with 128 neurons and rectifier activation function.\n",
    ">6. Finally, the output layer has 10 neurons for the 10 classes and a softmax activation function to output probability-like predictions for each class.\n",
    "\n",
    "Let me translate (with lots of help):\n",
    "1. CNNs can be thought of as a sliding window across an image (which actually occurs in parallel) where different portions of the image are fed to later hidden layers. So in effect, these later hidden layers are effectively learning some feature(s) of the image but across different portions of the image. In this case, that sliding window is of size 5X5 and we use 32 of them in total. The sliding window is actually handled by the convolutional layer which in this case is also our input layer, although more convolutional layers can be applied. For more on feature maps see https://www.quora.com/What-is-meant-by-feature-maps-in-convolutional-neural-networks. For more on convolutions see https://youtu.be/C_zFhWdM4ic.\n",
    "2. Pooling layers are effectively downsampling the image. This can improve convergence time as well as reduce overfitting. Intuitively, pooling happens once we know some features exist and where they are relative to each other, we do not need to preserve any more of the original data. See also http://cs231n.github.io/convolutional-networks/#pool and https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer.\n",
    "3. Dropout is a regularization technique. If you are new to machine learning, recall that regularization is a term for smoothing a function. This may lead to a lower training accuracy but is said to \"generalize\" better on test, validation, and real data. To better understand dropout, we should understand \"ensembling\" and \"bagging\". Imagine we have a few neural networks each trained on a subset of data that we average together. The use of multiple nets is known as \"ensembling\" while the specific use of subsetting the data and averaging the nets is known as \"bagging\". Dropout as a regularization technique, approximates this ensembling approach by changing the way the weights are changed during training. In each step of training, units are randomly removed while backprop occurs as usual with the effect of training multiple smaller networks on a subset. https://www.quora.com/How-does-the-dropout-method-work-in-deep-learning.\n",
    "4. Since the layers to this point operate in a higher dimensional space and we want a classifier in 1 dimension, we use a technique called flattening. https://www.quora.com/What-is-the-meaning-of-flattening-step-in-a-convolutional-neural-network.\n",
    "5. Another hidden layer is added, presumably this serves to improve performance of the network.\n",
    "6. The output layer needs to align to our classification problem (10 units for 10 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than the CNN components, nothing new is introduced. So we can now train and evaluate the model. This will take some time on a laptop. The original authors say this might take about 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "80s - loss: 0.2457 - acc: 0.9301 - val_loss: 0.0758 - val_acc: 0.9767\n",
      "Epoch 2/10\n",
      "80s - loss: 0.0731 - acc: 0.9781 - val_loss: 0.0498 - val_acc: 0.9848\n",
      "Epoch 3/10\n",
      "79s - loss: 0.0521 - acc: 0.9842 - val_loss: 0.0408 - val_acc: 0.9863\n",
      "Epoch 4/10\n",
      "78s - loss: 0.0420 - acc: 0.9868 - val_loss: 0.0377 - val_acc: 0.9871\n",
      "Epoch 5/10\n",
      "78s - loss: 0.0338 - acc: 0.9895 - val_loss: 0.0389 - val_acc: 0.9864\n",
      "Epoch 6/10\n",
      "78s - loss: 0.0277 - acc: 0.9913 - val_loss: 0.0398 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "78s - loss: 0.0243 - acc: 0.9925 - val_loss: 0.0361 - val_acc: 0.9874\n",
      "Epoch 8/10\n",
      "78s - loss: 0.0195 - acc: 0.9937 - val_loss: 0.0333 - val_acc: 0.9894\n",
      "Epoch 9/10\n",
      "80s - loss: 0.0165 - acc: 0.9949 - val_loss: 0.0402 - val_acc: 0.9881\n",
      "Epoch 10/10\n",
      "79s - loss: 0.0146 - acc: 0.9953 - val_loss: 0.0337 - val_acc: 0.9892\n",
      "Baseline Error: 1.08%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=0)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can definitely see an improvement in our error. While this is a good amount of work and a longer training time, a nearly 1% boost can be an incredible improvement for many applications. But the authors are not satisfied yet. We can build an even better model!\n",
    "\n",
    "## Larger CNN\n",
    "\n",
    "Building on the last CNN model, we can increase the size of the net a bit more. \n",
    "\n",
    "### Preprocessing for a larger CNN\n",
    "\n",
    "All of the imports are the same but we need to reset our data and pre-process it. This is certainly not the most efficient way of doing things on a large dataset but for MNIST this should be fine. The real computation and time cost comes during training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    " \n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the larger CNN model\n",
    "\n",
    "Recall our earlier model:\n",
    "\n",
    "1. Convolutional layer with 32 feature maps of size 5×5\n",
    "2. Pooling layer taking the max over 2×2 patches\n",
    "3. Dropout layer with a probability of 20%\n",
    "4. Flatten layer\n",
    "5. Fully connected layer with 128 neurons and rectifier activation function\n",
    "6. Output layer\n",
    "\n",
    "In this larger model, we have 3 more layers. We add an additional convolutional and pooling layer after the first two layers this time with fewer and smaller feature maps. We also add an additional fully connected (dense) layer between the original dense layer and the output layer.\n",
    "\n",
    "1. Convolutional layer with 30 feature maps of size 5×5\n",
    "2. Pooling layer taking the max over 2*2 patches\n",
    "3. Convolutional layer with 15 feature maps of size 3×3\n",
    "4. Pooling layer taking the max over 2*2 patches\n",
    "5. Dropout layer with a probability of 20%\n",
    "6. Flatten layer\n",
    "7. Fully connected layer with 128 neurons and rectifier activation\n",
    "8. Fully connected layer with 50 neurons and rectifier activation\n",
    "9. Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(30, 5, 5, border_mode='valid', input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(15, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caution: This model can take quite awhile to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 0.78%\n"
     ]
    }
   ],
   "source": [
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=0)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Larger CNN\n",
    "\n",
    "How did it do? Amazingly! Less than 1% error on a laptop CPU with a few minutes of training? Incredible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
